---
title: "Analysis of Ecological Footprint Dataset"
author: "Josip Domazet, Ivan Landeka, Sanja Deur, Filip Sodić"
date: '21 08 2019 '
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE, warning = F, message=F}
knitr::opts_chunk$set(echo = TRUE)
```

## About project

Our project consist of exploratory data analysis (EDA) and predictive analytics 
on 2016 Global Ecological Footprint dataset.
We choose this dataset since ecological footprint is very important measure which 
can tell us about magnitude of our impact on our planet.
Learning from ecological data can be very useful since it can point to variables which are 
hurting nature the most.

## Loading Packages

```{r,warning = F, message=F}
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(corrplot)
library(psych)
library(leaflet)
library(naniar) 
library(knitr)
library(kableExtra)
library(plotly)
library(cowplot)
library(caret)
library(randomForest)
library(rpart.plot)
library(rpart)
library(rgl)
```

## Know Your Data (and a bit of feature engineering)

```{r}
dat <- read.csv("data/countries.csv", encoding="UTF-8", stringsAsFactors = F)
glimpse(dat)
dat$GDP.per.Capita <-  as.numeric(gsub('[$,]', '', dat$GDP.per.Capita))

dat$Country <- as.factor(dat$Country)
dat$Region <- as.factor(dat$Region)

```
We can see that 19 of the columns are numeric types. Column GDP.per.Capita had to be converted to 
_double_ type. Other columns are factors. We will ommit _Data.Quality_ because we will not use it anywhere.

```{r}
dat$Data.Quality <- NULL
```

### Checking for missing data

It's always important to check for missing values and consider how to fix them.

```{r}
missing_data <- dat %>% summarise_all(funs(sum(is.na(.))/n()))
missing_data <- gather(missing_data, key = "variables", value = "percent_missing")
missing_data <- missing_data[missing_data$percent_missing > 0.0, ] 
ggplot(missing_data, aes(x = reorder(variables, percent_missing), y = percent_missing)) +
geom_bar(stat = "identity", fill = "red", aes(color = I('white')), size = 0.3)+
xlab('variables')+
coord_flip()+ 
theme_fivethirtyeight() +
  ggtitle("Missing Data By Columns",
          subtitle = "HDI has the highest percentage")

```

```{r}
table1_dat <- dat[is.na(dat$HDI), c(1,2)]
rownames(table1_dat) <- NULL
table1_dat %>% kable(caption = "Countries with missing data") %>%  kable_styling("striped", full_width = T) %>% row_spec(c(4,15), bold = T, background = "lightblue")
```
They are all pretty much small countries (with exceptions like Côte d'Ivoire, Somalia etc.) . 


## Data splitting & imputation

```{r}
indexes <- createDataPartition(dat$Total.Ecological.Footprint, list = F, p = 0.75)
dat_train <- dat[indexes, ]
dat_test <- dat[-indexes, ]

# RANDOM FOREST imputation
dat_train_imputed <- rfImpute(Total.Ecological.Footprint ~ Region + Population..millions. + HDI + GDP.per.Capita + Cropland + Grazing.Land + Forest.Land + Fishing.Water + Urban.Land + Total.Biocapacity, data = dat_train, iter = 20)

```


## Visualising all numeric columns

It's useful to show histograms of all numeric columns.

```{r}
multi.hist(dat[,sapply(dat, is.numeric)])
```

Most of the variables (Population..millions, Fishing.Water, etc.) are right skewed. 
We will inspect Total Ecological Footprint more detaily.

```{r}
dat %>% ggplot(aes(x = Total.Ecological.Footprint)) +
  geom_histogram(bins = 30, aes(y = ..density..), fill = "purple") + 
  geom_density(alpha = 0.2, fill = "purple") +
  theme_fivethirtyeight() +
  ggtitle("Total per Capita Footprint") +
  theme(axis.title = element_text(), axis.title.x = element_text()) +
  geom_vline(xintercept = mean(dat$Total.Ecological.Footprint), size = 2, linetype = 3) +
  annotate("text", x = 7, y = 0.35, label = "Average per Capita Footprint is 3.32")


```

## Biggest polluters

```{r}
dat %>% arrange(desc(Total.Ecological.Footprint)) %>% select(Total.Ecological.Footprint, Country) %>% head(n = 15) %>% dplyr::rename(Footprint_per_Person = Total.Ecological.Footprint) %>%
kable(caption = "Biggest polluters - by countries", col.names = c("Footprint per Person",
                           "Country")) %>%
    kable_styling("striped", full_width = F) %>%
  row_spec(1:5, bold = T, color = "white", background = "#D7261E")

```

## Smallest polluters

```{r}
dat %>% arrange((Total.Ecological.Footprint)) %>% select(Total.Ecological.Footprint, Country) %>% head(n = 15) %>% dplyr::rename(Footprint_per_Person = Total.Ecological.Footprint) %>%
kable(caption = "Smallest polluters - by countries", col.names = c("Footprint per Person",
                           "Country")) %>%
    kable_styling("striped", full_width = F) %>%
  row_spec(1:5, bold = T, color = "white", background = "#56AB6F")
```


## Visualising correlation

```{r}
k <- dat[, sapply(dat, is.numeric)]
k <- k[complete.cases(k), ]
korelacija <- cor(k)
corrplot(korelacija, method = "color", tl.cex = 0.825, title = "Pearson correlation", mar=c(0,0,1,0))
```
```{r}
k2 <- dat[, sapply(dat, is.numeric)]
k2 <- k2[complete.cases(k2), ]
korelacija2 <- cor(k2, method = "spearman") # izlaz je matrica
corrplot(korelacija2, method = "color", tl.cex = 0.825, title = "Spearman correlation", mar=c(0,0,1,0))
```

We can see that the results are different, 
so we can conclude that the linear relationship is probably not the best guess.

## Exploring by Regions

```{r}
dat %>% group_by(Region) %>% tally() %>% 
  ggplot(aes(x = reorder(Region, n), n)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  theme_fivethirtyeight() +
  ggtitle("Number of countries by regions") +
  geom_text(aes(x = Region, y = 1, label = paste0(n)),
            hjust=0.15, vjust=.5, size = 4, colour = 'black',
            fontface = 'bold') +
  coord_flip()
```



```{r, echo=FALSE}
dat %>% group_by(Region) %>% summarise(Total = sum(Total.Ecological.Footprint)) %>% 
  ggplot(aes(Region, Total, fill = Region)) + geom_histogram(stat = "identity") +
  theme_fivethirtyeight() +
  ggtitle("Total per Capita Footprint by Region") +
  theme(axis.text.x = element_text(angle = 20, vjust = 0.65))

```

## Linear regression

We will use linear regression to explain per capit footprint by serveral predictors.
Both economical and geographical features will be used.


### Economical Features
```{r}

linear_model1 <- lm(Total.Ecological.Footprint ~ HDI, data = dat)
summary(linear_model1)

linear_model2 <- lm(Total.Ecological.Footprint ~ I(exp(HDI)), data = dat)
summary(linear_model2)

linear_model3 <- lm(Total.Ecological.Footprint ~ HDI + I(HDI**2), data = dat)
summary(linear_model3)
 
slr <- ggplot(dat, aes(HDI, Total.Ecological.Footprint)) +
  geom_point(aes(text = Country)) +
  geom_smooth(method= "lm", color = "red", linetype = 1, se=F) +
  geom_smooth(method= "lm", formula = (y ~ x + I(x**2)), color = "blue", linetype = 2, se=F) +
  ggtitle("Simple Linear Regression",
          subtitle = "Model With Quadratic Term does much better") 

ggplotly(slr, tooltip="text")
```

```{r}
slr <- ggplot(dat, aes(GDP.per.Capita, Total.Ecological.Footprint)) +
  geom_point(aes(text = Country)) +
  geom_smooth(method= "lm", color = "red", linetype = 1, se=F) +
  geom_smooth(method= "lm", formula = (y ~ x + I(x**2)), color = "blue", linetype = 2, se=F) +
  ggtitle("Simple Linear Regression",
          subtitle = "Model With Quadratic Term does much better") 

ggplotly(slr, tooltip="text")
```


```{r}
ggplot(dat, aes(x = HDI, y = GDP.per.Capita)) +
  geom_point() +
  theme_fivethirtyeight() +
  ggtitle("HDI vs. GDP per Capita") +
   theme(axis.title = element_text(), axis.title.x = element_text())

```

It should be obvious that HDI and GDP are not linearly correlated.



```{r}
multiple1 <- lm(Total.Ecological.Footprint ~ GDP.per.Capita + HDI + I(GDP.per.Capita**2) + I(HDI**2) , data = dat)
summary(multiple1)
```

```{r}
ggplot(dat, aes(x = Population..millions., y = Total.Ecological.Footprint)) +
  geom_point() +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), axis.title.x = element_text()) +
  ggtitle("Using population as predictor",
          subtitle = "not really useful as predictor") +
  annotate("text", x = 800, y = 10,label = "Pearson correlation is -0.06", color = "red", size = 9)
```


## Geographical Features



```{r}

crops <- ggplot(dat, aes(x = Cropland, y = Total.Ecological.Footprint)) +
  geom_point(aes(size = Total.Ecological.Footprint), alpha = 0.4, color = "#e6a526") +  theme_fivethirtyeight() +
  ggtitle("Crop Land") +
   theme(axis.title = element_text(), axis.title.x = element_text(), legend.position="none")


urban <- ggplot(dat, aes(x = Urban.Land, y = Total.Ecological.Footprint)) +
  geom_point(aes(size = Total.Ecological.Footprint), alpha = 0.4, color = "#FF7F50")+
  theme_fivethirtyeight() +
  ggtitle("Urban Land") +
   theme(axis.title = element_text(), axis.title.x = element_text(), legend.position="none")

forest <- ggplot(dat, aes(x = Forest.Land, y = Total.Ecological.Footprint)) +
  geom_point(aes(size = Total.Ecological.Footprint), alpha = 0.4, color = "#56AB6F")+
  theme_fivethirtyeight() +
  ggtitle("Forest Land") +
   theme(axis.title = element_text(), axis.title.x = element_text(), legend.position="none")

fishing <- ggplot(dat, aes(x = Fishing.Water, y = Total.Ecological.Footprint)) +
  geom_point(aes(size = Total.Ecological.Footprint), alpha = 0.4, color = "#504FB1")+
  theme_fivethirtyeight() +
  ggtitle("Fishing Water") +
   theme(axis.title = element_text(), axis.title.x = element_text(), legend.position="none")


cowplot::plot_grid(urban, forest, fishing, crops, ncol = 2, nrow = 2,
                   label_y = "Total Footprint")

```
<br>
It can be seen increasing trends in all variables, except for _Forest Land_.


## Evaluating linear model

```{r}

HDI <- dat$HDI
GDP <- dat$GDP.per.Capita <- as.numeric(gsub('[$,]', '', dat$GDP.per.Capita))

final_multiple <- lm(Total.Ecological.Footprint ~ GDP.per.Capita + HDI + I(GDP.per.Capita**2) + I(HDI**2) , data = dat_train_imputed)
predicted <- predict(multiple1, newdata = dat_test)

open3d()

#plot datapoints GDP,HDI,ECO FOOTPRINT
# plot3d(predicted,HDI,GDP,col='red',xlab='Footprint',ylab='HDI',zlab ='GDP')
# #plot regression model as an approximation
# plot3d(dat$Total.Ecological.Footprint, HDI, GDP, col='blue', add = TRUE, xlab = 'Footprint', ylab='HDI', zlab='GDP')
knitr::include_graphics(c("visual/cube1.png", "visual/cube2.png"))

RMSE_mlr <- sqrt(mean((predicted[complete.cases(predicted)]- dat_test$Total.Ecological.Footprint[complete.cases(predicted)])**2))

```



## Regression Trees

```{r}
d_tree <- rpart(Total.Ecological.Footprint ~ Population..millions. + HDI + GDP.per.Capita + Cropland + Grazing.Land + Forest.Land + Fishing.Water + Urban.Land + Total.Biocapacity, data = dat_train_imputed)

rpart.plot(d_tree, main="Regression Tree", fallen.leaves=T, box.palette="GnBu")

predictions_d_tree <- predict(d_tree, newdata = dat_test)
RMSE_regression_tree <- sqrt(mean((predictions_d_tree[complete.cases(dat_test)] - dat_test$Total.Ecological.Footprint[complete.cases(dat_test)])**2))
```

## Random Forest Regression

We will use 10-fold cross validation to select optimal values for hyperparameters: _mtry_ (randomly selected variables) and _ntree_ (total number of trees in random forest)

```{r}
cv.10.folds <- createMultiFolds(dat_train_imputed, k = 10, times = 5) # cross-validation 10 folds
ctrl.1 <- trainControl(method = "repeatedcv", number = 10, repeats = 3, index = cv.10.folds)

rf_model <- train(Total.Ecological.Footprint ~ Population..millions. + HDI + GDP.per.Capita + Cropland + Grazing.Land + Forest.Land + Fishing.Water + Urban.Land + Total.Biocapacity, data = dat_train_imputed, method = "rf", trControl = ctrl.1, tuneLength = 5, importance = T)
importance <- varImp(rf_model)
finaldf <- importance$importance
variable_names <- rownames(finaldf)
finaldf$Variables <- variable_names
```

We can visualize importance of used predictors.

```{r}
ggplot(finaldf, aes(x = reorder(Variables, Overall), Overall)) +
geom_point(stat = "identity", size = 4, pch = 21, fill = "blue") +
geom_bar(stat = "identity", width = 0.075) +
xlab("Variables Names") +
coord_flip() +
theme_fivethirtyeight() +
ggtitle("Variables Ordered By Importance")
```

### Predicting values

```{r}
predictions_rf <- predict(rf_model, newdata = dat_test[complete.cases(dat_test), ])


y_real <- dat_test[complete.cases(dat_test), "Total.Ecological.Footprint"]

RMSE_rf <- sqrt(mean((predictions_rf - y_real)**2))

results <- tibble(
  x = y_real,
  y = predictions_rf,
  error = abs(y_real - predictions_rf)
)

ggplot(results, aes(x, y)) +
  geom_point(size = 3, shape = 1)  +
  geom_abline(slope = 1, intercept = 0, color = "blue", linetype = 2) +
  theme_fivethirtyeight() +
  ggtitle("Observed vs. Predicted") + 
  annotate("text", x = 5, y = 1.5, label = "RMSE = 1.17", color = "purple", size = 10)
```

We can see that random forest algorithm got better results than regression tree. That's not big of a surprise because random forests are well known for robustness and good scores.

## Summary of models

```{r}
models <- tibble(
  model_name = character(),
  RMSE = numeric()
)
models <- add_row(models, model_name = "Multiple linear regression", RMSE = RMSE_mlr)
models <- add_row(models, model_name = "Regression tree", RMSE = RMSE_regression_tree)
models <- add_row(models, model_name = "Random forests", RMSE = RMSE_rf)

models %>% kable(caption = "RMSE of different models") %>%  kable_styling("striped", full_width = T)
```


